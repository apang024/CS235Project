{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 235 - Pet Adoption Speed - Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This preprocessing was the same done in the group, so I used Ashley Pang's preprocessing code since the decision trees are the most similar to my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Type            Name  Age  Breed1  Breed2  Gender  Color1  Color2  \\\n",
      "0         2          Nibble    3     299       0       1       1       7   \n",
      "1         2     No Name Yet    1     265       0       1       1       2   \n",
      "2         1          Brisco    1     307       0       1       2       7   \n",
      "3         1            Miko    4     307       0       2       1       2   \n",
      "4         1          Hunter    1     307       0       1       1       0   \n",
      "...     ...             ...  ...     ...     ...     ...     ...     ...   \n",
      "14988     2             NaN    2     266       0       3       1       0   \n",
      "14989     2  Serato & Eddie   60     265     264       3       1       4   \n",
      "14990     2         Monkies    2     265     266       3       5       6   \n",
      "14991     2         Ms Daym    9     266       0       2       4       7   \n",
      "14992     1            Fili    1     307     307       1       2       0   \n",
      "\n",
      "       Color3  MaturitySize  ...  Health  Quantity  Fee  State  \\\n",
      "0           0             1  ...       1         1  100  41326   \n",
      "1           0             2  ...       1         1    0  41401   \n",
      "2           0             2  ...       1         1    0  41326   \n",
      "3           0             2  ...       1         1  150  41401   \n",
      "4           0             2  ...       1         1    0  41326   \n",
      "...       ...           ...  ...     ...       ...  ...    ...   \n",
      "14988       0             2  ...       1         4    0  41326   \n",
      "14989       7             2  ...       1         2    0  41326   \n",
      "14990       7             3  ...       1         5   30  41326   \n",
      "14991       0             1  ...       1         1    0  41336   \n",
      "14992       0             2  ...       1         1    0  41332   \n",
      "\n",
      "                              RescuerID  VideoAmt  \\\n",
      "0      8480853f516546f6cf33aa88cd76c379         0   \n",
      "1      3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
      "2      fa90fa5b1ee11c86938398b60abc32cb         0   \n",
      "3      9238e4f44c71a75282e62f7136c6b240         0   \n",
      "4      95481e953f8aed9ec3d16fc4509537e8         0   \n",
      "...                                 ...       ...   \n",
      "14988  61c84bd7bcb6fb31d2d480b1bcf9682e         0   \n",
      "14989  1d5096c4a5e159a3b750c5cfcf6ceabf         0   \n",
      "14990  6f40a7acfad5cc0bb3e44591ea446c05         0   \n",
      "14991  c311c0c569245baa147d91fa4e351ae4         0   \n",
      "14992  9ed1d5493d223eaa5024c1a031dbc9c2         0   \n",
      "\n",
      "                                             Description      PetID PhotoAmt  \\\n",
      "0      Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3      1.0   \n",
      "1      I just found it alone yesterday near my apartm...  6296e909a      2.0   \n",
      "2      Their pregnant mother was dumped by her irresp...  3422e4906      7.0   \n",
      "3      Good guard dog, very alert, active, obedience ...  5842f1ff5      8.0   \n",
      "4      This handsome yet cute boy is up for adoption....  850a43f90      3.0   \n",
      "...                                                  ...        ...      ...   \n",
      "14988  I have 4 kittens that need to be adopt urgentl...  dc0935a84      3.0   \n",
      "14989  Serato(female cat- 3 color) is 4 years old and...  a01ab5b30      3.0   \n",
      "14990  Mix breed, good temperament kittens. Love huma...  d981b6395      5.0   \n",
      "14991  she is very shy..adventures and independent..s...  e4da1c9e4      3.0   \n",
      "14992  Fili just loves laying around and also loves b...  a83d95ead      1.0   \n",
      "\n",
      "       AdoptionSpeed  \n",
      "0                  2  \n",
      "1                  0  \n",
      "2                  3  \n",
      "3                  2  \n",
      "4                  2  \n",
      "...              ...  \n",
      "14988              2  \n",
      "14989              4  \n",
      "14990              3  \n",
      "14991              4  \n",
      "14992              3  \n",
      "\n",
      "[14993 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read everything in\n",
    "df_train = pd.read_csv('petfinder-adoption-prediction/train/train.csv')\n",
    "df_breedLabels = pd.read_csv(\"petfinder-adoption-prediction/PetFinder-BreedLabels.csv\")\n",
    "df_colorLabels = pd.read_csv(\"petfinder-adoption-prediction/PetFinder-ColorLabels.csv\")\n",
    "df_stateLabels = pd.read_csv(\"petfinder-adoption-prediction/PetFinder-StateLabels.csv\")\n",
    "# df_test = pd.read_csv('petfinder-adoption-prediction/test/test.csv')\n",
    "\n",
    "# import pandas as pd\n",
    "# from google.colab import drive\n",
    "\n",
    "# # read everything in\n",
    "# drive.mount('/content/drive/', force_remount=True)\n",
    "# df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/train/train.csv')\n",
    "# df_breedLabels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/PetFinder-BreedLabels.csv')\n",
    "# df_colorLabels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/PetFinder-ColorLabels.csv')\n",
    "# df_stateLabels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/PetFinder-StateLabels.csv')\n",
    "# # df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/test/test.csv')\n",
    "\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 197 rows due to outliers. There are now 14796 rows in our training data.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df_train = df_train.drop(['Name', 'RescuerID', 'PetID', 'Description'], axis=1)\n",
    "df_breedLables = df_breedLabels.drop(['Type'], axis=1)\n",
    "\n",
    "# Drop rows with missing information\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Calculate z-score for only numerical columns\n",
    "z_scores_fee = np.abs(stats.zscore(df_train['Fee']))\n",
    "z_scores_age = np.abs(stats.zscore(df_train['Age']))\n",
    "\n",
    "# Using a threshold of 5 std dev. identify the outlier rows\n",
    "outlier_rows_fee = z_scores_fee > 5\n",
    "outlier_rows_age = z_scores_age > 5\n",
    "combined_outlier_rows = outlier_rows_fee | outlier_rows_age\n",
    "\n",
    "# Remove rows with outliers\n",
    "df_train = df_train[~combined_outlier_rows]\n",
    "print(f\"Removed {combined_outlier_rows.sum()} rows due to outliers. There are now {df_train.shape[0]} rows in our training data.\")\n",
    "# print(df_train.head())\n",
    "\n",
    "# Separate the resulting column from the training data\n",
    "adoption_speed_train = df_train.pop('AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 values for Breed1:\n",
      "307    5903\n",
      "266    3623\n",
      "265    1257\n",
      "299     342\n",
      "264     291\n",
      "292     262\n",
      "285     202\n",
      "141     199\n",
      "205     175\n",
      "218     161\n",
      "Name: Breed1, dtype: int64\n",
      "\n",
      "Top 10 values for Breed2:\n",
      "0      10613\n",
      "307     1723\n",
      "266      597\n",
      "265      321\n",
      "299      137\n",
      "264      116\n",
      "292      104\n",
      "218       91\n",
      "141       85\n",
      "285       76\n",
      "Name: Breed2, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separating categorical features\n",
    "binary_categorical_columns = ['Gender','Vaccinated','Dewormed', 'Sterilized']\n",
    "ordinal_categorical_columns = ['MaturitySize', 'FurLength', 'Health', 'Color1', 'Color2', 'Color3']\n",
    "nonordinal_categorical_columns = ['Breed1', 'Breed2']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_train = pd.get_dummies(df_train, columns=binary_categorical_columns)\n",
    "for column in ordinal_categorical_columns:\n",
    "  df_train[column] = label_encoder.fit_transform(df_train[column])\n",
    "\n",
    "# Split non-ordinal categorical columns into n features (similar to Benjamin's preprocessing)\n",
    "n = 10\n",
    "\n",
    "for feature in nonordinal_categorical_columns:\n",
    "  top_N_values = df_train[feature].value_counts().head(n)\n",
    "  print(f'Top {n} values for {feature}:\\n{top_N_values}\\n')\n",
    "\n",
    "  top_N_value_names = top_N_values.index\n",
    "  for index, row in df_train.iterrows():\n",
    "    # If value isn't top N frequency, replace with -1 (other)\n",
    "    if row[feature] not in top_N_value_names:\n",
    "      df_train.at[index, feature] = -1\n",
    "\n",
    "  df_train = pd.get_dummies(df_train, columns=[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split 85% training, 10% test, 5% validation\n",
    "df_train_85, X_temp, adoption_speed_train_85, y_temp = train_test_split(df_train, adoption_speed_train, test_size=0.15, random_state=42, stratify=adoption_speed_train)    # 85% training set, 15% temp set\n",
    "df_test_10, df_val_5, adoption_speed_test_10, adoption_speed_val_5 = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)       # 10% test set, 5% validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model\n",
    "\n",
    "Used for understanding Random Forest Classification:  \n",
    "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "\n",
    "How the Random Forest Model works:\n",
    "* Create n decision trees based on a subset of the training sample (using parameters).  \n",
    "* Pass test data into each decision tree and choose the average/majority result from those.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_85\n",
    "Y = adoption_speed_train_85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.3928912213740458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# Default Classifier (with random_state=2 for demonstration)\n",
    "classifier = RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=2)\n",
    "classifier.fit(X, Y)\n",
    "print('OOB score:', classifier.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Parameters Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training: 98.4%\n",
      "Accuracy on test: 38.4%\n",
      "Accuracy on validation: 40.5%\n",
      "Average weighted precision: 37.1%\n",
      "Average weighted recall: 38.4%\n",
      "Class 0: Precision = 15.4%, Recall = 5.0%\n",
      "Class 1: Precision = 33.900000000000006%, Recall = 34.1%\n",
      "Class 2: Precision = 35.8%, Recall = 37.8%\n",
      "Class 3: Precision = 32.5%, Recall = 23.200000000000003%\n",
      "Class 4: Precision = 46.5%, Recall = 57.099999999999994%\n"
     ]
    }
   ],
   "source": [
    "# method taken from Benjamin Denzler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "classifier = RandomForestClassifier(n_jobs=-1, oob_score=True)\t\t# removed random_state\n",
    "classifier.fit(df_train_85, adoption_speed_train_85)\n",
    "test_predictions = classifier.predict(df_test_10)\n",
    "\n",
    "accuracy = classifier.score(df_train_85, adoption_speed_train_85)\n",
    "print(f'Accuracy on training: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = classifier.score(df_test_10, adoption_speed_test_10)\n",
    "print(f'Accuracy on test: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = classifier.score(df_val_5, adoption_speed_val_5)\n",
    "print(f'Accuracy on validation: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "# zero_divison=0 returns 0 precision/recall if no positive samples for a class\n",
    "avg_precision = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "avg_recall = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "precision_per_class = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "recall_per_class = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "print(f'Average weighted precision: {round(avg_precision, 3) * 100}%')\n",
    "print(f'Average weighted recall: {round(avg_recall, 3) * 100}%')\n",
    "for class_label, precision, recall in zip(range(len(precision_per_class)), precision_per_class, recall_per_class):\n",
    "    print(f'Class {class_label}: Precision = {round(precision, 3) * 100}%, Recall = {round(recall, 3) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold validation accuracy mean: 39.5%\n",
      "10-fold validation precision mean: 38.4%\n",
      "10-fold validation recall mean: 39.5%\n"
     ]
    }
   ],
   "source": [
    "# validation method taken from Benjamin Denzler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(\n",
    "        precision_score, average='weighted', zero_division=0\n",
    "    ),\n",
    "    'recall': make_scorer(\n",
    "        recall_score, average='weighted', zero_division=0\n",
    "    )\n",
    "}\n",
    "\n",
    "scores = cross_validate(\n",
    "    classifier, df_train_85, adoption_speed_train_85,\n",
    "    cv=num_folds, scoring=scoring_metrics\n",
    ")\n",
    "\n",
    "print(f'\\n{num_folds}-fold validation accuracy mean: {round(scores[\"test_accuracy\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation precision mean: {round(scores[\"test_precision\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation recall mean: {round(scores[\"test_recall\"].mean(), 3) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters:  \n",
    "There are a few parameters that we can adjust to try to get closer to our goal.  \n",
    "* n_estimators - the number of decision trees created\n",
    "* max_features - the maximum number of features \n",
    "* min_samples_leaf - the minumum number of leaves required to split an internal node\n",
    "* criterion - the method used to split nodes (Entropy, Gini impurity, Log Loss)\n",
    "* max_leaf_nodes - maximum leaf nodes in a tree\n",
    "* max_depth - limit the amount of decisions we are doing per tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.3955947837150127\n"
     ]
    }
   ],
   "source": [
    "# Add hyperparameters to get a better accuracy\n",
    "classifier = RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=2, n_estimators=200, max_features=8)\n",
    "classifier.fit(X, Y)\n",
    "print('OOB score:', classifier.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearch, all combinations of predetermined hyperparameters are tested and the highest scoring classifier is used and returned.  \n",
    "n_estimators, max_features, and min_sample_leaf are iterated through. These parameters help scale the amount of information that is used when creating the decision trees.  \n",
    "Through testing, entropy was found to have the most success. max_leaf_nodes and max_depth both help limit the tree so that it does not overfit. However with the parameters and dataset given, making these values infinite (=None) increased the accuracy score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 125 candidates, totalling 625 fits\n",
      "0.41149867093148573 RandomForestClassifier(criterion='entropy', max_features=10, min_samples_leaf=5,\n",
      "                       n_estimators=300, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=-1,criterion='entropy')\n",
    "\n",
    "n_features = len(df_train_85.columns)\n",
    "#Hyperparameters\n",
    "params = {\t\t\t\t\t\t\t\t\t\t\t# defaults\n",
    "\t'n_estimators': [100,150,200,250,300],\t\t\t# 100\n",
    "\t'max_features': [5,10,15,20,30],\t\t\t\t# 'sqrt' = ~5\n",
    "\t'min_samples_leaf': [1,2,5,10,20],\t\t\t\t# 1\n",
    "\t# 'criterion': ['gini','entropy','log_loss'],\t\t# 'gini'\n",
    "\t# 'max_leaf_nodes': [50,100,150,200],\t\t\t\t# None\n",
    "\t# 'max_depth': [10,20,25,30]\t\t\t\t\t\t# None\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(estimator=classifier, param_grid=params, cv=5, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "gs.fit(X, Y)\n",
    "\n",
    "print(gs.best_score_, gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and Precision Metrics  \n",
    "These methods are used to see the accuracy, precision, and recall of our classifier. We also used a 10-fold cross validation as our validation statistic.  \n",
    "The method used were programmed by Benjamin Denzler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training: 69.19999999999999%\n",
      "Accuracy on test: 40.1%\n",
      "Accuracy on validation: 41.4%\n",
      "Average weighted precision: 40.5%\n",
      "Average weighted recall: 40.1%\n",
      "Class 0: Precision = 100.0%, Recall = 2.5%\n",
      "Class 1: Precision = 35.0%, Recall = 31.8%\n",
      "Class 2: Precision = 36.0%, Recall = 41.4%\n",
      "Class 3: Precision = 35.8%, Recall = 17.599999999999998%\n",
      "Class 4: Precision = 46.800000000000004%, Recall = 66.3%\n"
     ]
    }
   ],
   "source": [
    "# accuracy and precision method taken from Benjamin Denzler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "best_rfm = gs.best_estimator_\n",
    "best_rfm.fit(df_train_85, adoption_speed_train_85)\n",
    "test_predictions = best_rfm.predict(df_test_10)\n",
    "\n",
    "accuracy = best_rfm.score(df_train_85, adoption_speed_train_85)\n",
    "print(f'Accuracy on training: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = best_rfm.score(df_test_10, adoption_speed_test_10)\n",
    "print(f'Accuracy on test: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = best_rfm.score(df_val_5, adoption_speed_val_5)\n",
    "print(f'Accuracy on validation: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "# zero_divison=0 returns 0 precision/recall if no positive samples for a class\n",
    "avg_precision = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "avg_recall = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "precision_per_class = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "recall_per_class = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "print(f'Average weighted precision: {round(avg_precision, 3) * 100}%')\n",
    "print(f'Average weighted recall: {round(avg_recall, 3) * 100}%')\n",
    "for class_label, precision, recall in zip(range(len(precision_per_class)), precision_per_class, recall_per_class):\n",
    "    print(f'Class {class_label}: Precision = {round(precision, 3) * 100}%, Recall = {round(recall, 3) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold validation accuracy mean: 41.3%\n",
      "10-fold validation precision mean: 40.699999999999996%\n",
      "10-fold validation recall mean: 41.3%\n"
     ]
    }
   ],
   "source": [
    "# validation method taken from Benjamin Denzler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(\n",
    "        precision_score, average='weighted', zero_division=0\n",
    "    ),\n",
    "    'recall': make_scorer(\n",
    "        recall_score, average='weighted', zero_division=0\n",
    "    )\n",
    "}\n",
    "\n",
    "scores = cross_validate(\n",
    "    best_rfm, df_train_85, adoption_speed_train_85,\n",
    "    cv=num_folds, scoring=scoring_metrics\n",
    ")\n",
    "\n",
    "print(f'\\n{num_folds}-fold validation accuracy mean: {round(scores[\"test_accuracy\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation precision mean: {round(scores[\"test_precision\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation recall mean: {round(scores[\"test_recall\"].mean(), 3) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
