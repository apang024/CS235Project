{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 235 - Pet Adoption Speed - Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This preprocessing was the same done in the group, so I used Ashley Pang's preprocessing code since the decision trees are the most similar to my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Type            Name  Age  Breed1  Breed2  Gender  Color1  Color2  \\\n",
      "0         2          Nibble    3     299       0       1       1       7   \n",
      "1         2     No Name Yet    1     265       0       1       1       2   \n",
      "2         1          Brisco    1     307       0       1       2       7   \n",
      "3         1            Miko    4     307       0       2       1       2   \n",
      "4         1          Hunter    1     307       0       1       1       0   \n",
      "...     ...             ...  ...     ...     ...     ...     ...     ...   \n",
      "14988     2             NaN    2     266       0       3       1       0   \n",
      "14989     2  Serato & Eddie   60     265     264       3       1       4   \n",
      "14990     2         Monkies    2     265     266       3       5       6   \n",
      "14991     2         Ms Daym    9     266       0       2       4       7   \n",
      "14992     1            Fili    1     307     307       1       2       0   \n",
      "\n",
      "       Color3  MaturitySize  ...  Health  Quantity  Fee  State  \\\n",
      "0           0             1  ...       1         1  100  41326   \n",
      "1           0             2  ...       1         1    0  41401   \n",
      "2           0             2  ...       1         1    0  41326   \n",
      "3           0             2  ...       1         1  150  41401   \n",
      "4           0             2  ...       1         1    0  41326   \n",
      "...       ...           ...  ...     ...       ...  ...    ...   \n",
      "14988       0             2  ...       1         4    0  41326   \n",
      "14989       7             2  ...       1         2    0  41326   \n",
      "14990       7             3  ...       1         5   30  41326   \n",
      "14991       0             1  ...       1         1    0  41336   \n",
      "14992       0             2  ...       1         1    0  41332   \n",
      "\n",
      "                              RescuerID  VideoAmt  \\\n",
      "0      8480853f516546f6cf33aa88cd76c379         0   \n",
      "1      3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
      "2      fa90fa5b1ee11c86938398b60abc32cb         0   \n",
      "3      9238e4f44c71a75282e62f7136c6b240         0   \n",
      "4      95481e953f8aed9ec3d16fc4509537e8         0   \n",
      "...                                 ...       ...   \n",
      "14988  61c84bd7bcb6fb31d2d480b1bcf9682e         0   \n",
      "14989  1d5096c4a5e159a3b750c5cfcf6ceabf         0   \n",
      "14990  6f40a7acfad5cc0bb3e44591ea446c05         0   \n",
      "14991  c311c0c569245baa147d91fa4e351ae4         0   \n",
      "14992  9ed1d5493d223eaa5024c1a031dbc9c2         0   \n",
      "\n",
      "                                             Description      PetID PhotoAmt  \\\n",
      "0      Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3      1.0   \n",
      "1      I just found it alone yesterday near my apartm...  6296e909a      2.0   \n",
      "2      Their pregnant mother was dumped by her irresp...  3422e4906      7.0   \n",
      "3      Good guard dog, very alert, active, obedience ...  5842f1ff5      8.0   \n",
      "4      This handsome yet cute boy is up for adoption....  850a43f90      3.0   \n",
      "...                                                  ...        ...      ...   \n",
      "14988  I have 4 kittens that need to be adopt urgentl...  dc0935a84      3.0   \n",
      "14989  Serato(female cat- 3 color) is 4 years old and...  a01ab5b30      3.0   \n",
      "14990  Mix breed, good temperament kittens. Love huma...  d981b6395      5.0   \n",
      "14991  she is very shy..adventures and independent..s...  e4da1c9e4      3.0   \n",
      "14992  Fili just loves laying around and also loves b...  a83d95ead      1.0   \n",
      "\n",
      "       AdoptionSpeed  \n",
      "0                  2  \n",
      "1                  0  \n",
      "2                  3  \n",
      "3                  2  \n",
      "4                  2  \n",
      "...              ...  \n",
      "14988              2  \n",
      "14989              4  \n",
      "14990              3  \n",
      "14991              4  \n",
      "14992              3  \n",
      "\n",
      "[14993 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read everything in\n",
    "df_train = pd.read_csv('petfinder-adoption-prediction/train/train.csv')\n",
    "df_breedLabels = pd.read_csv(\"petfinder-adoption-prediction/PetFinder-BreedLabels.csv\")\n",
    "df_colorLabels = pd.read_csv(\"petfinder-adoption-prediction/PetFinder-ColorLabels.csv\")\n",
    "df_stateLabels = pd.read_csv(\"petfinder-adoption-prediction/PetFinder-StateLabels.csv\")\n",
    "# df_test = pd.read_csv('petfinder-adoption-prediction/test/test.csv')\n",
    "\n",
    "# import pandas as pd\n",
    "# from google.colab import drive\n",
    "\n",
    "# # read everything in\n",
    "# drive.mount('/content/drive/', force_remount=True)\n",
    "# df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/train/train.csv')\n",
    "# df_breedLabels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/PetFinder-BreedLabels.csv')\n",
    "# df_colorLabels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/PetFinder-ColorLabels.csv')\n",
    "# df_stateLabels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/PetFinder-StateLabels.csv')\n",
    "# # df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/petfinder-adoption-prediction/test/test.csv')\n",
    "\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 197 rows due to outliers. There are now 14796 rows in our training data.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df_train = df_train.drop(['Name', 'RescuerID', 'PetID', 'Description'], axis=1)\n",
    "df_breedLables = df_breedLabels.drop(['Type'], axis=1)\n",
    "\n",
    "# Drop rows with missing information\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Calculate z-score for only numerical columns\n",
    "z_scores_fee = np.abs(stats.zscore(df_train['Fee']))\n",
    "z_scores_age = np.abs(stats.zscore(df_train['Age']))\n",
    "\n",
    "# Using a threshold of 5 std dev. identify the outlier rows\n",
    "outlier_rows_fee = z_scores_fee > 5\n",
    "outlier_rows_age = z_scores_age > 5\n",
    "combined_outlier_rows = outlier_rows_fee | outlier_rows_age\n",
    "\n",
    "# Remove rows with outliers\n",
    "df_train = df_train[~combined_outlier_rows]\n",
    "print(f\"Removed {combined_outlier_rows.sum()} rows due to outliers. There are now {df_train.shape[0]} rows in our training data.\")\n",
    "# print(df_train.head())\n",
    "\n",
    "# Separate the resulting column from the training data\n",
    "adoption_speed_train = df_train.pop('AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 values for Breed1:\n",
      "307    5903\n",
      "266    3623\n",
      "265    1257\n",
      "299     342\n",
      "264     291\n",
      "292     262\n",
      "285     202\n",
      "141     199\n",
      "205     175\n",
      "218     161\n",
      "Name: Breed1, dtype: int64\n",
      "\n",
      "Top 10 values for Breed2:\n",
      "0      10613\n",
      "307     1723\n",
      "266      597\n",
      "265      321\n",
      "299      137\n",
      "264      116\n",
      "292      104\n",
      "218       91\n",
      "141       85\n",
      "285       76\n",
      "Name: Breed2, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separating categorical features\n",
    "binary_categorical_columns = ['Gender','Vaccinated','Dewormed', 'Sterilized']\n",
    "ordinal_categorical_columns = ['MaturitySize', 'FurLength', 'Health', 'Color1', 'Color2', 'Color3']\n",
    "nonordinal_categorical_columns = ['Breed1', 'Breed2']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_train = pd.get_dummies(df_train, columns=binary_categorical_columns)\n",
    "for column in ordinal_categorical_columns:\n",
    "  df_train[column] = label_encoder.fit_transform(df_train[column])\n",
    "\n",
    "# Split non-ordinal categorical columns into n features (similar to Benjamin's preprocessing)\n",
    "n = 10\n",
    "\n",
    "for feature in nonordinal_categorical_columns:\n",
    "  top_N_values = df_train[feature].value_counts().head(n)\n",
    "  print(f'Top {n} values for {feature}:\\n{top_N_values}\\n')\n",
    "\n",
    "  top_N_value_names = top_N_values.index\n",
    "  for index, row in df_train.iterrows():\n",
    "    # If value isn't top N frequency, replace with -1 (other)\n",
    "    if row[feature] not in top_N_value_names:\n",
    "      df_train.at[index, feature] = -1\n",
    "\n",
    "  df_train = pd.get_dummies(df_train, columns=[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split 85% training, 10% test, 5% validation\n",
    "df_train_85, X_temp, adoption_speed_train_85, y_temp = train_test_split(df_train, adoption_speed_train, test_size=0.15, random_state=42, stratify=adoption_speed_train)    # 85% training set, 15% temp set\n",
    "df_test_10, df_val_5, adoption_speed_test_10, adoption_speed_val_5 = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)       # 10% test set, 5% validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model (SKLearn)\n",
    "\n",
    "Used for understanding Random Forest Classification:  \n",
    "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "\n",
    "How the Random Forest Model works:\n",
    "* Create n decision trees based on a subset of the training sample (using parameters).  \n",
    "* Pass test data into each decision tree and choose the average/majority result from those.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_85\n",
    "Y = adoption_speed_train_85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.3928912213740458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# Default Classifier (with random_state=2 for demonstration)\n",
    "classifier = RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=2)\n",
    "classifier.fit(X, Y)\n",
    "print('OOB score:', classifier.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training: 98.4%\n",
      "Accuracy on test: 39.900000000000006%\n",
      "Accuracy on validation: 41.199999999999996%\n",
      "Average weighted precision: 38.7%\n",
      "Average weighted recall: 39.800000000000004%\n",
      "Class 0: Precision = 20.0%, Recall = 5.0%\n",
      "Class 1: Precision = 33.300000000000004%, Recall = 32.800000000000004%\n",
      "Class 2: Precision = 37.0%, Recall = 40.1%\n",
      "Class 3: Precision = 36.5%, Recall = 26.0%\n",
      "Class 4: Precision = 47.9%, Recall = 58.8%\n"
     ]
    }
   ],
   "source": [
    "# method taken from Benjamin Denzler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "classifier = RandomForestClassifier(n_jobs=-1, oob_score=True)\t\t# removed random_state\n",
    "classifier.fit(df_train_85, adoption_speed_train_85)\n",
    "test_predictions = classifier.predict(df_test_10)\n",
    "\n",
    "accuracy = classifier.score(df_train_85, adoption_speed_train_85)\n",
    "print(f'Accuracy on training: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = classifier.score(df_test_10, adoption_speed_test_10)\n",
    "print(f'Accuracy on test: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = classifier.score(df_val_5, adoption_speed_val_5)\n",
    "print(f'Accuracy on validation: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "# zero_divison=0 returns 0 precision/recall if no positive samples for a class\n",
    "avg_precision = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "avg_recall = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "precision_per_class = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "recall_per_class = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "print(f'Average weighted precision: {round(avg_precision, 3) * 100}%')\n",
    "print(f'Average weighted recall: {round(avg_recall, 3) * 100}%')\n",
    "for class_label, precision, recall in zip(range(len(precision_per_class)), precision_per_class, recall_per_class):\n",
    "    print(f'Class {class_label}: Precision = {round(precision, 3) * 100}%, Recall = {round(recall, 3) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold validation accuracy mean: 39.800000000000004%\n",
      "10-fold validation precision mean: 38.800000000000004%\n",
      "10-fold validation recall mean: 39.800000000000004%\n"
     ]
    }
   ],
   "source": [
    "# validation method taken from Benjamin Denzler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(\n",
    "        precision_score, average='weighted', zero_division=0\n",
    "    ),\n",
    "    'recall': make_scorer(\n",
    "        recall_score, average='weighted', zero_division=0\n",
    "    )\n",
    "}\n",
    "\n",
    "scores = cross_validate(\n",
    "    classifier, df_train_85, adoption_speed_train_85,\n",
    "    cv=num_folds, scoring=scoring_metrics\n",
    ")\n",
    "\n",
    "print(f'\\n{num_folds}-fold validation accuracy mean: {round(scores[\"test_accuracy\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation precision mean: {round(scores[\"test_precision\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation recall mean: {round(scores[\"test_recall\"].mean(), 3) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters:  \n",
    "There are a few parameters that we can adjust to try to get closer to our goal.  \n",
    "* n_estimators - the number of decision trees created\n",
    "* max_features - the maximum number of features \n",
    "* min_samples_leaf - the minumum number of leaves required to split an internal node\n",
    "* criterion - the method used to split nodes (Entropy, Gini impurity, Log Loss)\n",
    "* max_leaf_nodes - maximum leaf nodes in a tree\n",
    "* max_depth - limit the amount of decisions we are doing per tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.3955947837150127\n"
     ]
    }
   ],
   "source": [
    "# Add hyperparameters to get a better accuracy\n",
    "classifier = RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=2, n_estimators=200, max_features=8)\n",
    "classifier.fit(X, Y)\n",
    "print('OOB score:', classifier.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearch, all combinations of predetermined hyperparameters are tested and the highest scoring classifier is used and returned.  \n",
    "n_estimators, max_features, and min_sample_leaf are iterated through. These parameters help scale the amount of information that is used when creating the decision trees.  \n",
    "Through testing, entropy was found to have the most success. max_leaf_nodes and max_depth both help limit the tree so that it does not overfit. However with the parameters and dataset given, making these values infinite (=None) increased the accuracy score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eyeba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "240 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eyeba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\eyeba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\eyeba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\eyeba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\eyeba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.36235699 0.36172103\n",
      " 0.36418592 0.36283435 0.36418576 0.36402697 0.36442436 0.36418592\n",
      " 0.36537882 0.3620389  0.3642655  0.36378827        nan        nan\n",
      "        nan        nan 0.36362942 0.36299336 0.36609469 0.36537898\n",
      " 0.36362948 0.36490169 0.3630726  0.36442471 0.36211851 0.36307285\n",
      " 0.36681033 0.36545832        nan        nan        nan        nan\n",
      " 0.36156192 0.36609437 0.36267483 0.36299317 0.36124408 0.36529943\n",
      " 0.36267517 0.36362945 0.36362935 0.36315228 0.36474255 0.36466306\n",
      "        nan        nan        nan        nan 0.4006047  0.39933246\n",
      " 0.40259265 0.39837835 0.40052505 0.40036617 0.40179729 0.40314912\n",
      " 0.40084318 0.39949148 0.39965021 0.4015592         nan        nan\n",
      "        nan        nan 0.40132053 0.40243351 0.40338807 0.40004788\n",
      " 0.39662859 0.40171809 0.4026722  0.39837863 0.39980941 0.39750341\n",
      " 0.39949157 0.40163825        nan        nan        nan        nan\n",
      " 0.3984574  0.39774194 0.39853723 0.39869612 0.39718503 0.399253\n",
      " 0.39845774 0.39861682 0.39829857 0.40052546 0.39774175 0.39941218\n",
      "        nan        nan        nan        nan 0.4010819  0.40458031\n",
      " 0.40132003 0.40163831 0.40553528 0.40656863 0.40378502 0.40855642\n",
      " 0.40974898 0.41197587 0.41205568 0.40935181        nan        nan\n",
      "        nan        nan 0.40855607 0.40927203 0.41070325 0.40966942\n",
      " 0.40776167 0.40943101 0.40895388 0.40823861 0.40370597 0.40776113\n",
      " 0.40815896 0.4100672         nan        nan        nan        nan\n",
      " 0.40545506 0.40458122 0.40664838 0.40664759 0.40497846 0.4038646\n",
      " 0.40664857 0.40466059 0.40434196 0.40458088 0.40625051 0.40863642\n",
      "        nan        nan        nan        nan 0.39575472 0.39694719\n",
      " 0.40139977 0.39996877 0.40259344 0.40473989 0.40537582 0.40617096\n",
      " 0.40696596 0.40712551 0.4133277  0.40919358        nan        nan\n",
      "        nan        nan 0.40704602 0.40585283 0.41181711 0.41038516\n",
      " 0.40704586 0.40815903 0.40951041 0.41149848 0.4072844  0.41054484\n",
      " 0.40855696 0.40784075        nan        nan        nan        nan\n",
      " 0.40426253 0.40712498 0.40569451 0.40505814 0.40863623 0.40712548\n",
      " 0.40633048 0.40521681 0.40203634 0.40593185 0.40601219 0.40625127]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41332769677641623 RandomForestClassifier(max_depth=25, min_samples_split=10, n_estimators=200,\n",
      "                       n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "n_features = len(df_train_85.columns)\n",
    "#Hyperparameters\n",
    "params = {\t\t\t\t\t\t\t\t\t\t\t# defaults\n",
    "\t# 'n_estimators': [2]\n",
    "\t'n_estimators': [100,150,200,250],\t\t\t# 100\n",
    "\t'min_samples_split': [1,2,5,10],\t\t\t# 1\n",
    "\t'min_samples_leaf': [1,2,5],\t\t\t\t# 1\n",
    "\t'max_depth': [3,10,20,25]\t\t\t\t\t\t# None\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(estimator=classifier, param_grid=params, cv=5, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "gs.fit(X, Y)\n",
    "\n",
    "print(gs.best_score_, gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and Precision Metrics  \n",
    "These methods are used to see the accuracy, precision, and recall of our classifier. We also used a 10-fold cross validation as our validation statistic.  \n",
    "The method used were programmed by Benjamin Denzler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training: 82.3%\n",
      "Accuracy on test: 40.0%\n",
      "Accuracy on validation: 41.6%\n",
      "Average weighted precision: 39.1%\n",
      "Average weighted recall: 40.0%\n",
      "Class 0: Precision = 50.0%, Recall = 2.5%\n",
      "Class 1: Precision = 33.1%, Recall = 31.5%\n",
      "Class 2: Precision = 37.1%, Recall = 39.800000000000004%\n",
      "Class 3: Precision = 36.199999999999996%, Recall = 19.8%\n",
      "Class 4: Precision = 46.7%, Recall = 65.9%\n"
     ]
    }
   ],
   "source": [
    "# accuracy and precision method taken from Benjamin Denzler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "best_rfm = gs.best_estimator_\n",
    "best_rfm.fit(df_train_85, adoption_speed_train_85)\n",
    "test_predictions = best_rfm.predict(df_test_10)\n",
    "\n",
    "accuracy = best_rfm.score(df_train_85, adoption_speed_train_85)\n",
    "print(f'Accuracy on training: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = best_rfm.score(df_test_10, adoption_speed_test_10)\n",
    "print(f'Accuracy on test: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "accuracy = best_rfm.score(df_val_5, adoption_speed_val_5)\n",
    "print(f'Accuracy on validation: {round(accuracy, 3) * 100}%')\n",
    "\n",
    "# zero_divison=0 returns 0 precision/recall if no positive samples for a class\n",
    "avg_precision = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "avg_recall = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "precision_per_class = precision_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "recall_per_class = recall_score(\n",
    "    adoption_speed_test_10, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "print(f'Average weighted precision: {round(avg_precision, 3) * 100}%')\n",
    "print(f'Average weighted recall: {round(avg_recall, 3) * 100}%')\n",
    "for class_label, precision, recall in zip(range(len(precision_per_class)), precision_per_class, recall_per_class):\n",
    "    print(f'Class {class_label}: Precision = {round(precision, 3) * 100}%, Recall = {round(recall, 3) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold validation accuracy mean: 40.9%\n",
      "10-fold validation precision mean: 40.300000000000004%\n",
      "10-fold validation recall mean: 40.9%\n"
     ]
    }
   ],
   "source": [
    "# validation method taken from Benjamin Denzler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(\n",
    "        precision_score, average='weighted', zero_division=0\n",
    "    ),\n",
    "    'recall': make_scorer(\n",
    "        recall_score, average='weighted', zero_division=0\n",
    "    )\n",
    "}\n",
    "\n",
    "scores = cross_validate(\n",
    "    best_rfm, df_train_85, adoption_speed_train_85,\n",
    "    cv=num_folds, scoring=scoring_metrics\n",
    ")\n",
    "\n",
    "print(f'\\n{num_folds}-fold validation accuracy mean: {round(scores[\"test_accuracy\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation precision mean: {round(scores[\"test_precision\"].mean(), 3) * 100}%')\n",
    "print(f'{num_folds}-fold validation recall mean: {round(scores[\"test_recall\"].mean(), 3) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Implementation from Ashley Pang  \n",
    "https://colab.research.google.com/drive/1yHBau067-yP7q6b1TWQAmEk7WgKNaRdW#scrollTo=kxgZYzx3Y7j-&line=62&uniqifier=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations:\n",
    "- [SciKitLearn - Libraries for Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n",
    "- [SciKitLearn - Decision Tree Structure](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html)\n",
    "- [Datacamp -  Decision Tree Classification](https://www.datacamp.com/tutorial/decision-tree-classification-python) (For determining that CART uses the Gini index)\n",
    "- [GeeksforGeeks - Decision Tree](https://www.geeksforgeeks.org/decision-tree-implementation-python/)\n",
    "- [GeeksforGeeks - Gini Index](https://www.geeksforgeeks.org/gini-impurity-and-entropy-in-decision-tree-ml/)\n",
    "- [Youtube video on Decision Tree Classification from scratch](https://www.youtube.com/watch?v=sgQAhG5Q7iY&t=892s)\n",
    "- [GeeksforGeeks - Binary Tree Data Structure](https://www.geeksforgeeks.org/binary-tree-data-structure/)\n",
    "- [Auantinsti - How to Calculate Gini Index](https://blog.quantinsti.com/gini-index/)\n",
    "- [Baeldung - Splitting by Gini Index](https://www.baeldung.com/cs/impurity-entropy-gini-index)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Implement a Decision Tree from Scratch\n",
    "  # Hyperparameters to implement: max_depth=10 min_samples_split=2 min_samples_leaf=2\n",
    "  # Fit using these datasets: df_train_85, adoption_speed_train_85\n",
    "  # Predict the train, val and test sets (df_train_85, df_val_5, df_test_10)\n",
    "\n",
    "# Given the features (x) and correspondings class labels (y) (0-4) return the feature with the lowest gini index\n",
    "def FindMinGiniIndex(x, y):\n",
    "  # Get the num of columns in x\n",
    "  numOfColumns = 1\n",
    "  if x.ndim > 1:\n",
    "    numOfColumns = x.shape[1]\n",
    "\n",
    "  # Initialize all gini indexes to 1 which is the worst value\n",
    "  giniValues = np.ones(numOfColumns)\n",
    "\n",
    "  for curFeature in range(numOfColumns):\n",
    "    # Save all of the unique values in the column (look at all rows) and return the counts\n",
    "    curColumn = x[:]\n",
    "    if x.ndim > 1:\n",
    "      curColumn = x[:,curFeature]\n",
    "\n",
    "    # Remove any \"Not a number\" values for this column in x and in the result y\n",
    "    validRows = ~np.isnan(curColumn)\n",
    "    curColumnFiltered = curColumn[validRows]\n",
    "    yFiltered = y[validRows]\n",
    "\n",
    "    uniqueValues, counts = np.unique(curColumnFiltered, return_counts=True)\n",
    "\n",
    "    if len(uniqueValues) > 0:\n",
    "      curColGiniValues = np.ones(len(uniqueValues))\n",
    "      # Find the probability of the uniqueValue also being in a certain class\n",
    "      for i, uniqueVal in enumerate(uniqueValues):\n",
    "        # Use a dictionary to count occurences of each class\n",
    "        classCounts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
    "        for j, curVal in enumerate(curColumnFiltered):\n",
    "          if uniqueVal == curVal and y[j] in classCounts:\n",
    "            classCounts[yFiltered[j]] += 1\n",
    "\n",
    "        # Calculate the sum of squared probabilies of each class\n",
    "        probabilitySum = 0.0\n",
    "        totalCount = counts[i]\n",
    "        if totalCount > 0:\n",
    "          for j, curClassCount in classCounts.items():\n",
    "            probabilitySum += pow((curClassCount / totalCount), 2)\n",
    "        else:\n",
    "          probabilitySum = 0.0\n",
    "\n",
    "        # Calculate the current gini index for this unique value and save it in an array\n",
    "        # Gini Index = 1 - sum (squared probabilities of each outcome)\n",
    "        curColGiniValues[i] = 1 - probabilitySum\n",
    "\n",
    "      # Find the weighted sum of the gini indices for each unique Value\n",
    "      giniValues[curFeature] = 0\n",
    "      for i, curGiniVal in enumerate(curColGiniValues):\n",
    "        probOfCurUniqueValue = counts[i] / len(curColumnFiltered)\n",
    "        giniValues[curFeature] += (probOfCurUniqueValue) * curGiniVal\n",
    "\n",
    "  # Find the minimum gini index\n",
    "  minimumGiniIndex = np.min(giniValues)\n",
    "  featureToSplit = np.argmin(giniValues)\n",
    "\n",
    "  return minimumGiniIndex, featureToSplit\n",
    "\n",
    "def GetBestSplitUsingGiniIndex(x, y, min_samples_leaf):\n",
    "  # Find the feature to split\n",
    "  minimumGiniIndex, featureToSplit = FindMinGiniIndex(x, y)\n",
    "  colToSplit = x[:]\n",
    "  if x.ndim > 1:\n",
    "    colToSplit = x[:,featureToSplit]\n",
    "\n",
    "  uniqueValues = np.unique(colToSplit)\n",
    "  uniqueValues = np.sort(uniqueValues)\n",
    "  xLeftFinal = np.array([])\n",
    "  yLeftFinal = np.array([])\n",
    "  xRightFinal = np.array([])\n",
    "  yRightFinal = np.array([])\n",
    "  minimumGini = 1\n",
    "  bestThresh = uniqueValues[0]\n",
    "\n",
    "  # Find best threshold to split by\n",
    "  for i in range(1, len(uniqueValues)):\n",
    "    threshold = (uniqueValues[i - 1] / 2.0) + (uniqueValues[i] / 2.0)\n",
    "\n",
    "    # Split using the suggested threshold (average between two values in the array)\n",
    "    xLeft = colToSplit[colToSplit <= threshold]\n",
    "    yLeft = y[colToSplit <= threshold]\n",
    "    xRight = colToSplit[colToSplit > threshold]\n",
    "    yRight = y[colToSplit > threshold]\n",
    "    currMingini = 1\n",
    "\n",
    "    if ((len(xLeft) >= min_samples_leaf) and (len(xRight) >= min_samples_leaf)):\n",
    "      # Adjust the x to have left on the first column and right on the second column with filler None's:\n",
    "      #  xLeft = [[1]], xRight = [[15],[18]] then\n",
    "      #  xCombined = [[ 1     None]\n",
    "      #               [ None  15  ]\n",
    "      #               [ None  18  ]]\n",
    "      xLeftFiller = np.empty_like(xRight, dtype=float)\n",
    "      xLeftFiller.fill(np.nan)\n",
    "      xRightFiller = np.empty_like(xLeft, dtype=float)\n",
    "      xRightFiller.fill(np.nan)\n",
    "      xLeftTemp = np.concatenate((xLeft, xLeftFiller))\n",
    "      xRightTemp = np.concatenate((xRightFiller, xRight))\n",
    "      xCombined = np.zeros((len(xRightFiller) + len(xRight), 2))\n",
    "\n",
    "      xCombined[:, 0] = xLeftTemp\n",
    "      xCombined[:, 1] = xRightTemp\n",
    "\n",
    "      # Adjust y to just be on top of the other:\n",
    "      #  yLeft = [[1],[2]], yRight = [[3]] then\n",
    "      #  yCombined = [[1]\n",
    "      #               [2]\n",
    "      #               [3]]\n",
    "      yCombined = np.concatenate((yLeft, yRight))\n",
    "\n",
    "      # Calculate the gini index given first column is xLeft and second column is xRight\n",
    "      currMingini, column = FindMinGiniIndex(xCombined, yCombined)\n",
    "\n",
    "    # Keep updating the minimumGini and keep the best splits\n",
    "    if minimumGini > currMingini:\n",
    "      minimumGini = currMingini\n",
    "      bestThresh = threshold\n",
    "\n",
    "  validLeftRows = x[:] <= bestThresh\n",
    "  validRightRows = x[:] > bestThresh\n",
    "  if x.ndim > 1:\n",
    "    validLeftRows = x[:, featureToSplit] <= bestThresh\n",
    "    validRightRows = x[:, featureToSplit] > bestThresh\n",
    "\n",
    "  xLeftFinal = x[validLeftRows]\n",
    "  yLeftFinal = y[validLeftRows]\n",
    "  xRightFinal = x[validRightRows]\n",
    "  yRightFinal = y[validRightRows]\n",
    "\n",
    "  return xLeftFinal, yLeftFinal, xRightFinal, yRightFinal, featureToSplit, minimumGini, bestThresh\n",
    "\n",
    "def printSplit(xL, yL, xR, yR, split, gini, thresh):\n",
    "  print(f\"Split by feature column {split}, with gini index = {gini} and threshold <= {thresh}\")\n",
    "\n",
    "  print(\"XLeft:\")\n",
    "  print(xL)\n",
    "  print(\"YLeft:\")\n",
    "  print(yL)\n",
    "  print(\"\\nXRight:\")\n",
    "  print(xR)\n",
    "  print(\"YRight:\")\n",
    "  print(yR)\n",
    "  print(\"\\n\")\n",
    "\n",
    "class DecisionTreeNode:\n",
    "  def __init__(self, num, features, labels, featureToSplit, minimumGini, bestThresh):\n",
    "    self.x = features\n",
    "    self.y = labels\n",
    "    self.childLeft = None\n",
    "    self.childRight = None\n",
    "    self.feature = featureToSplit\n",
    "    self.giniIndex = minimumGini\n",
    "    self.threshold = bestThresh\n",
    "    self.majorityClass = self.calculateMajorityClass()\n",
    "\n",
    "  # Print the node and its children similar to sklearn's exportText function\n",
    "  def printNode(self, indent=\"\"):\n",
    "    if not self.isLeaf():\n",
    "      print(f\"{indent}|--- {self.feature} <= {self.threshold}, giniIndex = {self.giniIndex}\")\n",
    "      if self.childLeft is not None and self.childRight is not None:\n",
    "        if self.childLeft.isLeaf():\n",
    "          print(f\"{indent}|  |--- Class: {self.childLeft.majorityClass}\")\n",
    "        else:\n",
    "          self.childLeft.printNode(indent + \"|  \")\n",
    "      print(f\"{indent}|--- {self.feature} > {self.threshold}, giniIndex = {self.giniIndex}\")\n",
    "      if self.childLeft is not None and self.childRight is not None:\n",
    "        if self.childRight.isLeaf():\n",
    "          print(f\"{indent}|  |--- Class: {self.childRight.majorityClass}\")\n",
    "        else:\n",
    "          self.childRight.printNode(indent + \"|  \")\n",
    "\n",
    "  # For predicting, we assign each node with a class based on majority\n",
    "  def calculateMajorityClass(self):\n",
    "    if len(np.bincount(self.y)) > 0:            # needed as a change for validation\n",
    "      return np.argmax(np.bincount(self.y))\n",
    "    else:\n",
    "      return -1\n",
    "\n",
    "  # Boolean check to see if the current leaf is a child\n",
    "  def isLeaf(self):\n",
    "    return self.childLeft is None and self.childRight is None or (self.feature is None and self.threshold is None)\n",
    "\n",
    "# Build the tree given the hyperparameters\n",
    "class DecisionTree:\n",
    "  # Initialize the tree with nothing in all parameters\n",
    "  def __init__(self, root=None, numNodes=0, max_depth=None, min_samples_split=None, min_samples_leaf=None, columnNames=None):\n",
    "    self.root = root\n",
    "    self.numNodes = numNodes\n",
    "    self.columnNames = columnNames\n",
    "    self.max_depth = max_depth\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "  # Define a fit function that builds the tree and uses the recursive call (starts with the root)\n",
    "  def fit(self, x, y):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "      x = x.to_numpy()\n",
    "    if not isinstance(y, np.ndarray):\n",
    "      y = y.to_numpy()\n",
    "    # Call this once and it will create the full tree\n",
    "    self.root = self.BuildTreeRecursive(x, y, self.max_depth, self.min_samples_split, self.min_samples_leaf, self.columnNames, 0)\n",
    "\n",
    "  # The recursive function that will stop once we meet the hyperparameter conditions\n",
    "  def BuildTreeRecursive(self, x, y, max_depth, min_samples_split, min_samples_leaf, columnNames, depth):\n",
    "    # Stop if we reached max_depth, or not enough samples to split or if everything in y is one class\n",
    "    if depth == max_depth or len(x) < min_samples_split or len(np.unique(y)) == 1:\n",
    "      # This is a child node\n",
    "      return DecisionTreeNode(self.numNodes, x, y, None, None, None)\n",
    "\n",
    "    else:\n",
    "      # Define the current node which is the parent\n",
    "      XLeft, YLeft, XRight, YRight, featureToSplit, minimumGini, bestThresh  = GetBestSplitUsingGiniIndex(x, y, min_samples_leaf)\n",
    "      parentNode = DecisionTreeNode(self.numNodes, x, y, columnNames[featureToSplit], minimumGini, bestThresh)\n",
    "      self.numNodes += 1\n",
    "\n",
    "      # Recursively create the children (left and right)\n",
    "      parentNode.childLeft = self.BuildTreeRecursive(XLeft, YLeft, max_depth, min_samples_split, min_samples_leaf, columnNames, depth + 1)\n",
    "      parentNode.childRight = self.BuildTreeRecursive(XRight, YRight, max_depth, min_samples_split, min_samples_leaf, columnNames, depth + 1)\n",
    "\n",
    "      # After returning from all of the recursive calls, return the root parent node\n",
    "      return parentNode\n",
    "\n",
    "  # Return an array of predictions of what class the row should be\n",
    "  def predict(self, features):\n",
    "    if not isinstance(features, np.ndarray):\n",
    "      features = features.to_numpy()\n",
    "    numRows = features.shape[0]\n",
    "    prediction = np.zeros((numRows, 1))\n",
    "\n",
    "    # Save prediction after tracing through the tree\n",
    "    for row in range(numRows):\n",
    "      curNode = self.root\n",
    "\n",
    "      # Check every non-leaf node and keep going through the branches\n",
    "      while not curNode.isLeaf():\n",
    "        # Make sure that the features passed in are what the tree was trained on\n",
    "        try:\n",
    "          column = self.columnNames.index(curNode.feature)\n",
    "        except ValueError:\n",
    "          raise ValueError(f\"Feature '{curNode.feature}' not found in trained DecisionTree.\")\n",
    "        if features[row, column] <= curNode.threshold:\n",
    "          curNode = curNode.childLeft\n",
    "        else:\n",
    "          curNode = curNode.childRight\n",
    "\n",
    "      # This node's prediction is based on its majorityClass\n",
    "      prediction[row, 0] = curNode.majorityClass\n",
    "\n",
    "    return prediction\n",
    "\n",
    "  # Calls print on the root and that node's print function will recursively call the rest of the node's prints\n",
    "  def PrintTree(self):\n",
    "    if self.root is not None:\n",
    "      self.root.printNode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main methodology for the random forest is splitting the data that is passed into the decision trees. The decision tree classifier was implemented by Ashley Pang, so all that needed to be done was the bagging method.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference page: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html  \n",
    "Setting params to dict: https://stackoverflow.com/questions/64918714/fastest-way-to-assign-variables-to-python-class  \n",
    "Random Forest from Scratch Reference: https://machinelearningmastery.com/implement-random-forest-scratch-python/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import multiprocessing\n",
    "# use:\n",
    "# classifier = RandForest(n_jobs=-1, oob_score=True, random_state=2)\n",
    "# classifier.fit(X, Y)\n",
    "class RandForest:\n",
    "\thyperparams = {}\n",
    "\tforest = list()\n",
    "\toob_score = 0.0\n",
    "\n",
    "\tdef __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None, oob_score=False, random_state=None):\n",
    "\t\tself.hyperparams['n_estimators']=n_estimators\t\t\t\t# number of trees created\n",
    "\t\tself.hyperparams['max_depth']=max_depth\t\t\t\t\t# implemented from decision tree\n",
    "\t\tself.hyperparams['min_samples_split']=min_samples_split\t# implemented from decision tree\n",
    "\t\tself.hyperparams['min_samples_leaf']=min_samples_leaf\t\t# implemented from decision tree\n",
    "\t\tself.hyperparams['max_features']=max_features\n",
    "\t\tself.hyperparams['oob_score']=oob_score\t\t\t\t\t# accuracy score\n",
    "\t\tself.hyperparams['random_state']=random_state\t\t\t\t# random state (seed)\n",
    "\t\n",
    "\t#used for GridSearch\n",
    "\tdef get_params(self, deep=True):\n",
    "\t\treturn self.hyperparams\n",
    "\tdef set_params(self, **params):\n",
    "\t\tfor i in params.keys():\n",
    "\t\t\tself.hyperparams[i] = params[i]\n",
    "\t\treturn self\n",
    "\t# Calculate accuracy percentage\n",
    "\tdef accuracy(self, actual, predict):\n",
    "\t\tcorrect = 0\n",
    "\t\tfor i in range(len(actual)):\n",
    "\t\t\tif actual.iloc[i] == predict[i]:\n",
    "\t\t\t\tcorrect += 1\n",
    "\t\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "\t# create subsample using ratio\n",
    "\tdef subsample(self, data, data_class, ratio):\n",
    "\t\tsample = pd.DataFrame(columns=X.columns)\n",
    "\t\tsample_class = list()\n",
    "\t\tsample_size = round(len(data)*ratio)\n",
    "\t\twhile len(sample) < sample_size:\n",
    "\t\t\tindex = randrange(0, len(data.index))\n",
    "\t\t\tsample.loc[len(sample.index)] = data.iloc[index]\t#https://www.geeksforgeeks.org/how-to-add-one-row-in-an-existing-pandas-dataframe/\n",
    "\t\t\tsample_class.append(data_class.iloc[index])\n",
    "\t\treturn sample, pd.Series(sample_class)\n",
    "\t\n",
    "\t# for all trees, get result from each, output max for each row\n",
    "\t# https://www.educative.io/answers/find-the-maximum-value-in-each-row-and-column-of-a-numpy-2d-array\n",
    "\tdef bagging(self, features):\n",
    "\t\tpredictions = list()\n",
    "\t\tfor tree in self.forest:\n",
    "\t\t\tp = tree.predict(features)\n",
    "\t\t\tpredictions.append(p)\n",
    "\t\tresults = np.amax(np.array(predictions), axis = 0)\n",
    "\t\treturn results\n",
    "\t\n",
    "\t# fit forest trees with subsamples\n",
    "\tdef fit(self, X, Y, sample_ratio=0.8):\n",
    "\t\tif self.hyperparams['random_state'] != None:\n",
    "\t\t\tseed(self.hyperparams['random_state'])\n",
    "\t\tself.forest = list()\n",
    "\t\tfor i in range(self.hyperparams['n_estimators']):\n",
    "\t\t\tsample, sample_class = self.subsample(X, Y, sample_ratio)\n",
    "\t\t\ttree = DecisionTree(max_depth=self.hyperparams['max_depth'], \n",
    "\t\t\t\t\t   \t\t\tmin_samples_split=self.hyperparams['min_samples_split'], \n",
    "\t\t\t\t\t\t\t\tmin_samples_leaf=self.hyperparams['min_samples_leaf'], \n",
    "\t\t\t\t\t\t\t\tcolumnNames=X.columns.tolist())\n",
    "\t\t\ttree.fit(sample, sample_class)\n",
    "\t\t\tself.forest.append(tree)\n",
    "\t\tif self.hyperparams['oob_score'] == True:\n",
    "\t\t\tpredictions = self.predict(X).tolist()\n",
    "\t\t\tself.oob_score = self.accuracy(Y, predictions)\n",
    "\t\treturn self\n",
    "\n",
    "\t# given inputs (rows with features), output array of predicted values\n",
    "\tdef predict(self, features):\n",
    "\t\tif not isinstance(features, np.ndarray):\n",
    "\t\t\tfeatures = features.to_numpy()\n",
    "\t\treturn self.bagging(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandForest() is initialize with hyper-parameters, although these can be changed/obtained using set_params() and get_params() respectively.\n",
    "* We have a dictionary to store the hyper-parameters as well as the forest of decision trees created during fitting and the oob_score.\n",
    "* We have subsample(), which will return a subsample of the data passed in, as well as the results.\n",
    "* bagging() will aggregate all of the forest's prediction results and return the array of predictions for each row of the input.\n",
    "* fit() will use the X and Y inputs to create n_estimator decision trees based on the hyper-parameters. If oob_score is set to true, we can also spend time calculating the accuracy of this fit based on itself.\n",
    "* accuracy() will iterate through all actual and predicted results and return the fraction of results that turned out to be correct.\n",
    "* predict() will take the input feature set and pass it into the bagging function. THe result is output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.43066157760814"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation using Ashley Pang's chosen hyperparameters (using two trees)\n",
    "classifier = RandForest(n_estimators=2,max_depth=10,min_samples_split=2,min_samples_leaf=2,oob_score=True, random_state=2)\n",
    "classifier.fit(X,Y)\n",
    "classifier.oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.06679389312977 2\n"
     ]
    }
   ],
   "source": [
    "# Use a sample of n_estimator values to find the best one to use\n",
    "# classifier = RandForest(max_depth=10,min_samples_split=2,min_samples_leaf=2,oob_score=True)\n",
    "n_features = len(df_train_85.columns)\n",
    "\n",
    "est_val = [2,5,10]\n",
    "scores = list()\n",
    "for i in est_val:\n",
    "\tclassifier = RandForest(n_estimators=i,max_depth=10,min_samples_split=2,min_samples_leaf=2,oob_score=True)\n",
    "\tclassifier.fit(X,Y)\n",
    "\tscores.append(classifier.oob_score)\n",
    "n_est = max(scores)\n",
    "print(n_est,scores.index(n_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation method taken from Ashley Pang and Benjamin Denzler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default\n",
      "10-fold validation accuracy mean: 0.39475357710651826\n",
      "10-fold validation precision mean: 0.3852302876434262\n",
      "10-fold validation recall mean: 0.39475357710651826\n",
      "Pruned\n",
      "10-fold validation accuracy mean: 0.40802861685214625\n",
      "10-fold validation precision mean: 0.40272442075465575\n",
      "10-fold validation recall mean: 0.40802861685214625\n",
      "Implementation\n",
      "\n",
      "10-fold validation accuracy mean: 0.3491255961844197\n",
      "10-fold validation precision mean: 0.29488343192544464\n",
      "10-fold validation recall mean: 0.3491255961844197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def cross_validate_manual(model, x, y, cv, scoring, random_seed=None):\n",
    "  # Initialization of the used variables\n",
    "  accuracy_list = []\n",
    "  precision_list = []\n",
    "  recall_list = []\n",
    "  np.random.seed(random_seed)\n",
    "\n",
    "  # Per split\n",
    "  for i in range(cv):\n",
    "    # set the random seed and then split using it\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1/cv, random_state=random_seed)\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_val)\n",
    "\n",
    "    # Look at each metric that we have passed in and choose a scoring function, only works for the three below\n",
    "    for metric in scoring:\n",
    "      if metric == 'accuracy':\n",
    "        accuracyScore = accuracy_score(y_val, predictions)\n",
    "        accuracy_list.append(accuracyScore)\n",
    "      elif metric == 'precision':\n",
    "        precisionScore = precision_score(y_val, predictions, average='weighted', zero_division=0)\n",
    "        precision_list.append(precisionScore)\n",
    "      elif metric == 'recall':\n",
    "        recallScore = recall_score(y_val, predictions, average='weighted', zero_division=0)\n",
    "        recall_list.append(recallScore)\n",
    "\n",
    "  # Populate the result with the three lists kept\n",
    "  result_dictionary = {\n",
    "    'test_accuracy': accuracy_list,\n",
    "    'test_precision': precision_list,\n",
    "    'test_recall': recall_list\n",
    "  }\n",
    "\n",
    "  return result_dictionary\n",
    "\n",
    "\n",
    "# Perform Cross Valdiation on default and pre-pruned decision trees\n",
    "# Uses skLearn's model with Ashley's cross validation function\n",
    "scoring_metrics = ['accuracy','precision','recall']\n",
    "scores_skLearn = cross_validate_manual(RandomForestClassifier(), df_train_85, adoption_speed_train_85, cv=10, scoring=scoring_metrics)\n",
    "print(\"Default\")\n",
    "print(f'10-fold validation accuracy mean: {np.mean(scores_skLearn[\"test_accuracy\"])}')\n",
    "print(f'10-fold validation precision mean: {np.mean(scores_skLearn[\"test_precision\"])}')\n",
    "print(f'10-fold validation recall mean: {np.mean(scores_skLearn[\"test_recall\"])}')\n",
    "\n",
    "scoring_metrics = ['accuracy','precision','recall']\n",
    "# scores_skLearn = cross_validate_manual(RandomForestClassifier(n_estimators=300,min_samples_split=2,min_samples_leaf=5), df_train_85, adoption_speed_train_85, cv=10, scoring=scoring_metrics)\n",
    "scores_skLearn = cross_validate_manual(gs.best_estimator_, df_train_85, adoption_speed_train_85, cv=10, scoring=scoring_metrics)\n",
    "print(\"Pruned\")\n",
    "print(f'10-fold validation accuracy mean: {np.mean(scores_skLearn[\"test_accuracy\"])}')\n",
    "print(f'10-fold validation precision mean: {np.mean(scores_skLearn[\"test_precision\"])}')\n",
    "print(f'10-fold validation recall mean: {np.mean(scores_skLearn[\"test_recall\"])}')\n",
    "\n",
    "# Uses a manual implementation of cross validation and model\n",
    "# Parameters: (model, x, y, cv, scoring)\n",
    "scoring_metrics = ['accuracy','precision','recall']\n",
    "scores_manualImp = cross_validate_manual(RandForest(n_estimators=10,max_depth=10,min_samples_split=2,min_samples_leaf=2), df_train_85, adoption_speed_train_85, cv=10, scoring=scoring_metrics)\n",
    "print(\"Implementation\")\n",
    "print(f'\\n10-fold validation accuracy mean: {np.mean(scores_manualImp[\"test_accuracy\"])}')\n",
    "print(f'10-fold validation precision mean: {np.mean(scores_manualImp[\"test_precision\"])}')\n",
    "print(f'10-fold validation recall mean: {np.mean(scores_manualImp[\"test_recall\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value_accuracy = 1.4729835726087444e-05\n",
      "p_value_precision = 5.766159235844788e-06\n",
      "p_value_recall = 1.4729835726087444e-05\n"
     ]
    }
   ],
   "source": [
    "# Taken from Benjamin Denzler\n",
    "# Perform T-test for statistical significance between sklearn and manual implementation with hyperparameters\n",
    "t_stat_accuracy, p_value_accuracy = stats.ttest_rel(scores_skLearn[\"test_accuracy\"], scores_manualImp[\"test_accuracy\"])\n",
    "t_stat_precision, p_value_precision = stats.ttest_rel(scores_skLearn[\"test_precision\"], scores_manualImp[\"test_precision\"])\n",
    "t_stat_recall, p_value_recall = stats.ttest_rel(scores_skLearn[\"test_recall\"], scores_manualImp[\"test_recall\"])\n",
    "\n",
    "print(f'p_value_accuracy = {p_value_accuracy}')\n",
    "print(f'p_value_precision = {p_value_precision}')\n",
    "print(f'p_value_recall = {p_value_recall}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
