{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ye3TbByrD4K"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL6b69L9cJYv"
      },
      "source": [
        "Mount Google Drive folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX1bhEPeTK6D",
        "outputId": "9972cf4f-a56e-4fb9-9efc-e6e2799824d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enable displaying all columns when we print dataframes."
      ],
      "metadata": {
        "id": "j7EqxaO3ponp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display all columns in output\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "PtV8yjYzpimT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import training data. Change path if needed."
      ],
      "metadata": {
        "id": "ct1vlkRTsQHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = '/content/drive/MyDrive/petfinder-adoption-prediction/train.csv'\n",
        "df = pd.read_csv(TRAIN_PATH)"
      ],
      "metadata": {
        "id": "sJbZnPCisLEM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Pre-Processing\n",
        "\n",
        "These are the pre-processing steps that the whole team followed:\n",
        "- Drop unnecessary columns:\n",
        "  - `Name` was dropped because it has many missing values.\n",
        "  - `RescuerID` and `PetID` were dropped because they provide no meaning to our models.\n",
        "  - `Description` was dropped because we are not intending to do sentiment analysis on text for our project.\n",
        "- Drop rows with missing data.\n",
        "- Remove outliers for `Fee` and `Age` (numerical values). Outliers are those at least 5 standard deviations above the average for a column."
      ],
      "metadata": {
        "id": "3oYCUajEa-JF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt6CctAXcGvg",
        "outputId": "2bb85724-d66e-471f-931b-9a47b3c78db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
            "0         2    3     299       0       1       1       7       0   \n",
            "1         2    1     265       0       1       1       2       0   \n",
            "2         1    1     307       0       1       2       7       0   \n",
            "3         1    4     307       0       2       1       2       0   \n",
            "4         1    1     307       0       1       1       0       0   \n",
            "...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
            "14988     2    2     266       0       3       1       0       0   \n",
            "14989     2   60     265     264       3       1       4       7   \n",
            "14990     2    2     265     266       3       5       6       7   \n",
            "14991     2    9     266       0       2       4       7       0   \n",
            "14992     1    1     307     307       1       2       0       0   \n",
            "\n",
            "       MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n",
            "0                 1          1           2         2           2       1   \n",
            "1                 2          2           3         3           3       1   \n",
            "2                 2          2           1         1           2       1   \n",
            "3                 2          1           1         1           2       1   \n",
            "4                 2          1           2         2           2       1   \n",
            "...             ...        ...         ...       ...         ...     ...   \n",
            "14988             2          2           2         2           2       1   \n",
            "14989             2          2           1         1           1       1   \n",
            "14990             3          2           2         1           3       1   \n",
            "14991             1          1           1         1           1       1   \n",
            "14992             2          1           2         2           2       1   \n",
            "\n",
            "       Quantity  Fee  State  VideoAmt  PhotoAmt  AdoptionSpeed  \n",
            "0             1  100  41326         0       1.0              2  \n",
            "1             1    0  41401         0       2.0              0  \n",
            "2             1    0  41326         0       7.0              3  \n",
            "3             1  150  41401         0       8.0              2  \n",
            "4             1    0  41326         0       3.0              2  \n",
            "...         ...  ...    ...       ...       ...            ...  \n",
            "14988         4    0  41326         0       3.0              2  \n",
            "14989         2    0  41326         0       3.0              4  \n",
            "14990         5   30  41326         0       5.0              3  \n",
            "14991         1    0  41336         0       3.0              4  \n",
            "14992         1    0  41332         0       1.0              3  \n",
            "\n",
            "[14796 rows x 20 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['Name', 'RescuerID', 'PetID', 'Description']\n",
        "df = df.drop(columns=columns_to_drop, axis=1)  # 1 refers to columns\n",
        "\n",
        "# Drop rows with missing data\n",
        "df = df.dropna()\n",
        "\n",
        "# Find z-scores for numerical columns\n",
        "z_scores_fee = np.abs(stats.zscore(df['Fee']))\n",
        "z_scores_age = np.abs(stats.zscore(df['Age']))\n",
        "\n",
        "# Find outliers based on threshold of 5 std. deviations\n",
        "outlier_rows_fee = z_scores_fee > 5\n",
        "outlier_rows_age = z_scores_age > 5\n",
        "combined_outlier_rows = outlier_rows_fee | outlier_rows_age\n",
        "\n",
        "# Remove outliers\n",
        "df = df[~combined_outlier_rows]\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm9YPRFMnAYt"
      },
      "source": [
        "# Neural Network Pre-Processing\n",
        "\n",
        "This is pre-processing that is specific to my neural network model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg-oi6z4tNJZ"
      },
      "source": [
        "Scale numerical attributes with `StandardScaler`. According to the `scikit-learn` [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), `StandardScaler` should be used to scale numerical attributes for input to a machine learning estimator. This is to prevent features with large values from dominating the learning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIP0pcpjnL4s",
        "outputId": "59bc0c43-5135-49ff-839b-7c700e486fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Age  Quantity       Fee  VideoAmt  PhotoAmt\n",
            "0     -0.430954 -0.393225  1.515422 -0.164405 -0.828418\n",
            "1     -0.558874 -0.393225 -0.308343 -0.164405 -0.542567\n",
            "2     -0.558874 -0.393225 -0.308343 -0.164405  0.886685\n",
            "3     -0.366994 -0.393225  2.427305 -0.164405  1.172536\n",
            "4     -0.558874 -0.393225 -0.308343 -0.164405 -0.256717\n",
            "...         ...       ...       ...       ...       ...\n",
            "14988 -0.494914  1.633300 -0.308343 -0.164405 -0.256717\n",
            "14989  3.214782  0.282284 -0.308343 -0.164405 -0.256717\n",
            "14990 -0.494914  2.308808  0.238787 -0.164405  0.314984\n",
            "14991 -0.047192 -0.393225 -0.308343 -0.164405 -0.256717\n",
            "14992 -0.558874 -0.393225 -0.308343 -0.164405 -0.828418\n",
            "\n",
            "[14796 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_to_scale = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n",
        "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
        "print(df[features_to_scale])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ7-j_fzE_e5"
      },
      "source": [
        "One-hot encode non-binary categorical features with `pd.get_dummies()`, documentation is [here](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html). The below columns have values [1, 2, 3] for \"Yes\", \"No\", and \"Not Sure\". The one-hot encoding is done to prevent the neural network from assuming 1 < 2 < 3 for these values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEblyAbDET2g",
        "outputId": "b983ff54-b998-43dc-81ae-d78f4ecf1ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Age  Breed1  Breed2  Color1  Color2  Color3  MaturitySize  \\\n",
            "0     -0.430954     299       0       1       7       0             1   \n",
            "1     -0.558874     265       0       1       2       0             2   \n",
            "2     -0.558874     307       0       2       7       0             2   \n",
            "3     -0.366994     307       0       1       2       0             2   \n",
            "4     -0.558874     307       0       1       0       0             2   \n",
            "...         ...     ...     ...     ...     ...     ...           ...   \n",
            "14988 -0.494914     266       0       1       0       0             2   \n",
            "14989  3.214782     265     264       1       4       7             2   \n",
            "14990 -0.494914     265     266       5       6       7             3   \n",
            "14991 -0.047192     266       0       4       7       0             1   \n",
            "14992 -0.558874     307     307       2       0       0             2   \n",
            "\n",
            "       FurLength  Health  Quantity       Fee  State  VideoAmt  PhotoAmt  \\\n",
            "0              1       1 -0.393225  1.515422  41326 -0.164405 -0.828418   \n",
            "1              2       1 -0.393225 -0.308343  41401 -0.164405 -0.542567   \n",
            "2              2       1 -0.393225 -0.308343  41326 -0.164405  0.886685   \n",
            "3              1       1 -0.393225  2.427305  41401 -0.164405  1.172536   \n",
            "4              1       1 -0.393225 -0.308343  41326 -0.164405 -0.256717   \n",
            "...          ...     ...       ...       ...    ...       ...       ...   \n",
            "14988          2       1  1.633300 -0.308343  41326 -0.164405 -0.256717   \n",
            "14989          2       1  0.282284 -0.308343  41326 -0.164405 -0.256717   \n",
            "14990          2       1  2.308808  0.238787  41326 -0.164405  0.314984   \n",
            "14991          1       1 -0.393225 -0.308343  41336 -0.164405 -0.256717   \n",
            "14992          1       1 -0.393225 -0.308343  41332 -0.164405 -0.828418   \n",
            "\n",
            "       AdoptionSpeed  Type_1  Type_2  Gender_1  Gender_2  Gender_3  \\\n",
            "0                  2       0       1         1         0         0   \n",
            "1                  0       0       1         1         0         0   \n",
            "2                  3       1       0         1         0         0   \n",
            "3                  2       1       0         0         1         0   \n",
            "4                  2       1       0         1         0         0   \n",
            "...              ...     ...     ...       ...       ...       ...   \n",
            "14988              2       0       1         0         0         1   \n",
            "14989              4       0       1         0         0         1   \n",
            "14990              3       0       1         0         0         1   \n",
            "14991              4       0       1         0         1         0   \n",
            "14992              3       1       0         1         0         0   \n",
            "\n",
            "       Vaccinated_1  Vaccinated_2  Vaccinated_3  Dewormed_1  Dewormed_2  \\\n",
            "0                 0             1             0           0           1   \n",
            "1                 0             0             1           0           0   \n",
            "2                 1             0             0           1           0   \n",
            "3                 1             0             0           1           0   \n",
            "4                 0             1             0           0           1   \n",
            "...             ...           ...           ...         ...         ...   \n",
            "14988             0             1             0           0           1   \n",
            "14989             1             0             0           1           0   \n",
            "14990             0             1             0           1           0   \n",
            "14991             1             0             0           1           0   \n",
            "14992             0             1             0           0           1   \n",
            "\n",
            "       Dewormed_3  Sterilized_1  Sterilized_2  Sterilized_3  \n",
            "0               0             0             1             0  \n",
            "1               1             0             0             1  \n",
            "2               0             0             1             0  \n",
            "3               0             0             1             0  \n",
            "4               0             0             1             0  \n",
            "...           ...           ...           ...           ...  \n",
            "14988           0             0             1             0  \n",
            "14989           0             1             0             0  \n",
            "14990           0             0             0             1  \n",
            "14991           0             1             0             0  \n",
            "14992           0             0             1             0  \n",
            "\n",
            "[14796 rows x 29 columns]\n"
          ]
        }
      ],
      "source": [
        "features_to_encode = ['Type', 'Gender', 'Vaccinated', 'Dewormed', 'Sterilized']\n",
        "df = pd.get_dummies(df, columns=features_to_encode)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWbxTrG5HUY1"
      },
      "source": [
        "Split `Breed1`, `Breed2`, and `State` features into N features each based on frequency of values.\n",
        "\n",
        "The breed columns have 306 unique values that have been label encoded, [1, 2, ..., 306]. We don't want the neural network to think there's a relationship between the numbers, like 100 < 101, but we can't one-hot encode because we will have too many columns.\n",
        "\n",
        "Instead, we create a column for each of the top 3 most common values, and another for \"other\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ3yHrwsIEKt",
        "outputId": "4b67c6c8-772e-4203-ae95-bdb9e5c9f671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 values for Breed1:\n",
            "307    5903\n",
            "266    3623\n",
            "265    1257\n",
            "Name: Breed1, dtype: int64\n",
            "\n",
            "Top 3 values for Breed2:\n",
            "0      10613\n",
            "307     1723\n",
            "266      597\n",
            "Name: Breed2, dtype: int64\n",
            "\n",
            "Top 3 values for State:\n",
            "41326    8595\n",
            "41401    3800\n",
            "41327     830\n",
            "Name: State, dtype: int64\n",
            "\n",
            "            Age  Color1  Color2  Color3  MaturitySize  FurLength  Health  \\\n",
            "0     -0.430954       1       7       0             1          1       1   \n",
            "1     -0.558874       1       2       0             2          2       1   \n",
            "2     -0.558874       2       7       0             2          2       1   \n",
            "3     -0.366994       1       2       0             2          1       1   \n",
            "4     -0.558874       1       0       0             2          1       1   \n",
            "...         ...     ...     ...     ...           ...        ...     ...   \n",
            "14988 -0.494914       1       0       0             2          2       1   \n",
            "14989  3.214782       1       4       7             2          2       1   \n",
            "14990 -0.494914       5       6       7             3          2       1   \n",
            "14991 -0.047192       4       7       0             1          1       1   \n",
            "14992 -0.558874       2       0       0             2          1       1   \n",
            "\n",
            "       Quantity       Fee  VideoAmt  PhotoAmt  AdoptionSpeed  Type_1  Type_2  \\\n",
            "0     -0.393225  1.515422 -0.164405 -0.828418              2       0       1   \n",
            "1     -0.393225 -0.308343 -0.164405 -0.542567              0       0       1   \n",
            "2     -0.393225 -0.308343 -0.164405  0.886685              3       1       0   \n",
            "3     -0.393225  2.427305 -0.164405  1.172536              2       1       0   \n",
            "4     -0.393225 -0.308343 -0.164405 -0.256717              2       1       0   \n",
            "...         ...       ...       ...       ...            ...     ...     ...   \n",
            "14988  1.633300 -0.308343 -0.164405 -0.256717              2       0       1   \n",
            "14989  0.282284 -0.308343 -0.164405 -0.256717              4       0       1   \n",
            "14990  2.308808  0.238787 -0.164405  0.314984              3       0       1   \n",
            "14991 -0.393225 -0.308343 -0.164405 -0.256717              4       0       1   \n",
            "14992 -0.393225 -0.308343 -0.164405 -0.828418              3       1       0   \n",
            "\n",
            "       Gender_1  Gender_2  Gender_3  Vaccinated_1  Vaccinated_2  Vaccinated_3  \\\n",
            "0             1         0         0             0             1             0   \n",
            "1             1         0         0             0             0             1   \n",
            "2             1         0         0             1             0             0   \n",
            "3             0         1         0             1             0             0   \n",
            "4             1         0         0             0             1             0   \n",
            "...         ...       ...       ...           ...           ...           ...   \n",
            "14988         0         0         1             0             1             0   \n",
            "14989         0         0         1             1             0             0   \n",
            "14990         0         0         1             0             1             0   \n",
            "14991         0         1         0             1             0             0   \n",
            "14992         1         0         0             0             1             0   \n",
            "\n",
            "       Dewormed_1  Dewormed_2  Dewormed_3  Sterilized_1  Sterilized_2  \\\n",
            "0               0           1           0             0             1   \n",
            "1               0           0           1             0             0   \n",
            "2               1           0           0             0             1   \n",
            "3               1           0           0             0             1   \n",
            "4               0           1           0             0             1   \n",
            "...           ...         ...         ...           ...           ...   \n",
            "14988           0           1           0             0             1   \n",
            "14989           1           0           0             1             0   \n",
            "14990           1           0           0             0             0   \n",
            "14991           1           0           0             1             0   \n",
            "14992           0           1           0             0             1   \n",
            "\n",
            "       Sterilized_3  Breed1_-1  Breed1_265  Breed1_266  Breed1_307  Breed2_-1  \\\n",
            "0                 0          1           0           0           0          0   \n",
            "1                 1          0           1           0           0          0   \n",
            "2                 0          0           0           0           1          0   \n",
            "3                 0          0           0           0           1          0   \n",
            "4                 0          0           0           0           1          0   \n",
            "...             ...        ...         ...         ...         ...        ...   \n",
            "14988             0          0           0           1           0          0   \n",
            "14989             0          0           1           0           0          1   \n",
            "14990             1          0           1           0           0          0   \n",
            "14991             0          0           0           1           0          0   \n",
            "14992             0          0           0           0           1          0   \n",
            "\n",
            "       Breed2_0  Breed2_266  Breed2_307  State_-1  State_41326  State_41327  \\\n",
            "0             1           0           0         0            1            0   \n",
            "1             1           0           0         0            0            0   \n",
            "2             1           0           0         0            1            0   \n",
            "3             1           0           0         0            0            0   \n",
            "4             1           0           0         0            1            0   \n",
            "...         ...         ...         ...       ...          ...          ...   \n",
            "14988         1           0           0         0            1            0   \n",
            "14989         0           0           0         0            1            0   \n",
            "14990         0           1           0         0            1            0   \n",
            "14991         1           0           0         1            0            0   \n",
            "14992         0           0           1         1            0            0   \n",
            "\n",
            "       State_41401  \n",
            "0                0  \n",
            "1                1  \n",
            "2                0  \n",
            "3                1  \n",
            "4                0  \n",
            "...            ...  \n",
            "14988            0  \n",
            "14989            0  \n",
            "14990            0  \n",
            "14991            0  \n",
            "14992            0  \n",
            "\n",
            "[14796 rows x 38 columns]\n"
          ]
        }
      ],
      "source": [
        "n = 3\n",
        "features_to_split = ['Breed1', 'Breed2', 'State']\n",
        "\n",
        "for feature in features_to_split:\n",
        "  top_N_values = df[feature].value_counts().head(n)\n",
        "  print(f'Top {n} values for {feature}:\\n{top_N_values}\\n')\n",
        "\n",
        "  top_N_value_names = top_N_values.index\n",
        "  for index, row in df.iterrows():\n",
        "    # If value isn't top N frequency, replace with -1 (other)\n",
        "    if row[feature] not in top_N_value_names:\n",
        "      df.at[index, feature] = -1\n",
        "\n",
        "  df = pd.get_dummies(df, columns=[feature])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfM9swyu-ZWz"
      },
      "source": [
        "# Neural Network Testing\n",
        "\n",
        "Set up neural network testing and training data. 85% is training, 10% is validation, and 5% is test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u9Tckb6b-YUK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "target_feature = 'AdoptionSpeed'\n",
        "features = df.drop(columns=[target_feature])\n",
        "target = df[target_feature]\n",
        "\n",
        "# Split training data, 15% is for testing & validation\n",
        "x_train, x_test_val, y_train, y_test_val = train_test_split(\n",
        "    features, target, test_size=0.15, shuffle=True,\n",
        "    stratify=target, random_state=42\n",
        ")\n",
        "\n",
        "# 5% of data is training, 10% is validation\n",
        "x_test, x_val, y_test, y_val = train_test_split(\n",
        "    x_test_val, y_test_val, test_size=1/3, shuffle=True,\n",
        "    stratify=y_test_val, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCqwzXSyr1dn"
      },
      "source": [
        "Fit the neural network and assess accuracy on training, validation, and test sets.\n",
        "\n",
        "- `max-iter` was set to 500 to prevent the neural network from giving up due to too many iterations.\n",
        "\n",
        "- `hidden_layer_sizes` was determined after experimenting with different parameters with `GridSearchCV`. I ran a grid search on my local machine with a variety of layer sizes and found that `(38, 5)` gave the highest accuracy on test and validation data. 38 corresponds to the number of input features, and 5 corresponds to the number of categories we're predicting.\n",
        "\n",
        "- The `solver` of `adam` was kept because the `scikit-learn` [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) recommends `adam` for datasets with thousands of samples or more. I considered using the solver `lbfgs`, but the neural network with `lbfgs` never converged.\n",
        "\n",
        "- `random_state` was set to 42 to make the predictions reproducible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6O0HXOor1do",
        "outputId": "d91ad19d-9c1d-4e99-cb9f-2a8c1dece17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training: 45.0%\n",
            "Accuracy on validation: 40.0%\n",
            "\n",
            "Accuracy on test: 38.7%\n",
            "Average weighted precision: 36.9%\n",
            "Average weighted recall: 38.7%\n",
            "Class 0: Precision = 0.0%, Recall = 0.0%\n",
            "Class 1: Precision = 30.9%, Recall = 29.5%\n",
            "Class 2: Precision = 33.7%, Recall = 43.1%\n",
            "Class 3: Precision = 37.7%, Recall = 13.3%\n",
            "Class 4: Precision = 47.4%, Recall = 64.9%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "classifier = MLPClassifier(\n",
        "    max_iter=500,\n",
        "    hidden_layer_sizes=(38, 5),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit to training data and make predictions on test data\n",
        "classifier.fit(x_train, y_train)\n",
        "test_predictions = classifier.predict(x_test)\n",
        "\n",
        "accuracy = classifier.score(x_train, y_train)\n",
        "print(f'Accuracy on training: {round(accuracy, 3) * 100}%')\n",
        "\n",
        "accuracy = classifier.score(x_val, y_val)\n",
        "print(f'Accuracy on validation: {round(accuracy, 3) * 100}%\\n')\n",
        "\n",
        "accuracy = classifier.score(x_test, y_test)\n",
        "print(f'Accuracy on test: {round(accuracy, 3) * 100}%')\n",
        "\n",
        "# zero_divison=0 returns 0 precision/recall if no positive samples for a class\n",
        "avg_precision = precision_score(\n",
        "    y_test, test_predictions, average='weighted', zero_division=0\n",
        ")\n",
        "avg_recall = recall_score(\n",
        "    y_test, test_predictions, average='weighted', zero_division=0\n",
        ")\n",
        "precision_per_class = precision_score(\n",
        "    y_test, test_predictions, average=None, zero_division=0\n",
        ")\n",
        "recall_per_class = recall_score(\n",
        "    y_test, test_predictions, average=None, zero_division=0\n",
        ")\n",
        "\n",
        "print(f'Average weighted precision: {round(avg_precision, 3) * 100}%')\n",
        "print(f'Average weighted recall: {round(avg_recall, 3) * 100}%')\n",
        "for class_label, precision, recall in zip(range(len(precision_per_class)), precision_per_class, recall_per_class):\n",
        "    print(f'Class {class_label}: Precision = {round(precision, 3) * 100}%, Recall = {round(recall, 3) * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Perform k-fold cross validation for modified parameters."
      ],
      "metadata": {
        "id": "6pd8moBOp5NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "num_folds = 10\n",
        "\n",
        "scoring_metrics = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(\n",
        "        precision_score, average='weighted', zero_division=0\n",
        "    ),\n",
        "    'recall': make_scorer(\n",
        "        recall_score, average='weighted', zero_division=0\n",
        "    )\n",
        "}\n",
        "\n",
        "scores = cross_validate(\n",
        "    classifier, x_train, y_train,\n",
        "    cv=num_folds, scoring=scoring_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "8-rlkjjwp3cH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output cross-validation accuracy, precision, and recall (weighted averages)."
      ],
      "metadata": {
        "id": "p6WeK1r4xEZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\n{num_folds}-fold validation accuracy mean: {round(scores[\"test_accuracy\"].mean(), 3) * 100}%')\n",
        "print(f'{num_folds}-fold validation precision mean: {round(scores[\"test_precision\"].mean(), 3) * 100}%')\n",
        "print(f'{num_folds}-fold validation recall mean: {round(scores[\"test_recall\"].mean(), 3) * 100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiSLVWqgwy9u",
        "outputId": "b19fe2b1-9ee1-4006-88ac-1957491d17d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10-fold validation accuracy mean: 37.8%\n",
            "10-fold validation precision mean: 35.9%\n",
            "10-fold validation recall mean: 37.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating the same experiment with a default instance of `MLPClassifier`. `max_iter` was changed to 500 because the default value would not converge."
      ],
      "metadata": {
        "id": "9leSiYICr6pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MLPClassifier(max_iter=500, random_state=42)\n",
        "\n",
        "# Fit to training data and make predictions on test data\n",
        "classifier.fit(x_train, y_train)\n",
        "test_predictions = classifier.predict(x_test)\n",
        "\n",
        "accuracy = classifier.score(x_train, y_train)\n",
        "print(f'Accuracy on training: {round(accuracy, 3) * 100}%')\n",
        "\n",
        "accuracy = classifier.score(x_val, y_val)\n",
        "print(f'Accuracy on validation: {round(accuracy, 3) * 100}%\\n')\n",
        "\n",
        "accuracy = classifier.score(x_test, y_test)\n",
        "print(f'Accuracy on test: {round(accuracy, 3) * 100}%')\n",
        "\n",
        "# zero_divison=0 returns 0 precision/recall if no positive samples for a class\n",
        "avg_precision = precision_score(\n",
        "    y_test, test_predictions, average='weighted', zero_division=0\n",
        ")\n",
        "avg_recall = recall_score(\n",
        "    y_test, test_predictions, average='weighted', zero_division=0\n",
        ")\n",
        "precision_per_class = precision_score(\n",
        "    y_test, test_predictions, average=None, zero_division=0\n",
        ")\n",
        "recall_per_class = recall_score(\n",
        "    y_test, test_predictions, average=None, zero_division=0\n",
        ")\n",
        "\n",
        "print(f'Average weighted precision: {round(avg_precision, 3) * 100}%')\n",
        "print(f'Average weighted recall: {round(avg_recall, 3) * 100}%')\n",
        "for class_label, precision, recall in zip(range(len(precision_per_class)), precision_per_class, recall_per_class):\n",
        "    print(f'Class {class_label}: Precision = {round(precision, 3) * 100}%, Recall = {round(recall, 3) * 100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DsJSENYr6Ug",
        "outputId": "9b5c784c-1c7c-4c8d-e630-55a801cbc14d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training: 51.2%\n",
            "Accuracy on validation: 40.699999999999996%\n",
            "\n",
            "Accuracy on test: 37.1%\n",
            "Average weighted precision: 35.3%\n",
            "Average weighted recall: 37.1%\n",
            "Class 0: Precision = 0.0%, Recall = 0.0%\n",
            "Class 1: Precision = 30.5%, Recall = 23.9%\n",
            "Class 2: Precision = 33.0%, Recall = 38.6%\n",
            "Class 3: Precision = 35.9%, Recall = 21.4%\n",
            "Class 4: Precision = 44.0%, Recall = 61.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Perform k-fold cross validation for default parameters."
      ],
      "metadata": {
        "id": "Hhlr0T7l3eWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "num_folds = 10\n",
        "\n",
        "scoring_metrics = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(\n",
        "        precision_score, average='weighted', zero_division=0\n",
        "    ),\n",
        "    'recall': make_scorer(\n",
        "        recall_score, average='weighted', zero_division=0\n",
        "    )\n",
        "}\n",
        "\n",
        "scores = cross_validate(\n",
        "    classifier, x_train, y_train,\n",
        "    cv=num_folds, scoring=scoring_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "QdKHouuR3WrL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output cross-validation accuracy, precision, and recall (weighted averages)."
      ],
      "metadata": {
        "id": "0Yizr0dS3iHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\n{num_folds}-fold validation accuracy mean: {round(scores[\"test_accuracy\"].mean(), 3) * 100}%')\n",
        "print(f'{num_folds}-fold validation precision mean: {round(scores[\"test_precision\"].mean(), 3) * 100}%')\n",
        "print(f'{num_folds}-fold validation recall mean: {round(scores[\"test_recall\"].mean(), 3) * 100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r34TWmRU3YR9",
        "outputId": "bd797e27-81ff-406c-c5e9-8ccd87e11e3b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10-fold validation accuracy mean: 36.199999999999996%\n",
            "10-fold validation precision mean: 34.9%\n",
            "10-fold validation recall mean: 36.199999999999996%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}